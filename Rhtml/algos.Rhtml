<!DOCTYPE html>
<html>
<head>
  <title>Algorithm performance overview</title>
</head>
<body>


<h2> Overview of performance values </h2>

The following statistics were calculated from the performance values of each algorithm:
<ul>

  <li> <a>obs (number of observations within performance values)</a>
  <li> <a>nas (number of NAs, i.e., missing values, within performance values)</a>
  <li> <a>min (minimum), mean (arithmetic mean), max (maximum), sd (standard deviation)</a>
  <li> <a>qu_1st (1st quartile = lower quartile = 25%-quantile)</a>
  <li> <a>med (median = 50%-quantile)</a>
  <li> <a>qu_3rd (3rd quartile = upper quartile = 75%-quantile)</a>
  <li> <a>coeff_var (coefficient of variation = standard deviation / arithmetic mean)</a>

</ul>

<!--begin.rcode, results = "asis"
  res = summarizeAlgoPerf(asscenario)
  print(xtable(res, digits = 6, display = c("s", "d", "d", rep("g", 8))), "html")
end.rcode-->

<br>
<h2> Summary of the runstatus per algorithm </h2>

The following table summarizes the runstatus of each algorithm over all instances (in %).<br>
<br>

<!--begin.rcode, results = "asis"
  res = summarizeAlgoRunstatus(asscenario)
  print(xtable(res, digits = 3), "html")
end.rcode-->

<br>
<h2> Dominated Algorithms </h2>

Here, you'll find an overview of dominating/dominated algorithms: <br>

<!--begin.rcode, results = "asis"
  res = findDominatedAlgos(asscenario, reduce = TRUE, type = "character")
  if (nrow(res) != 0) {
    print(xtable(res), include.rownames = TRUE, "html")
  } else {
    cat("None of the algorithms was superior to any of the other.")
  }
end.rcode-->

<br> <br>
An algorithm (A) is considered to be superior to an other algorithm (B), if it has at least an equal performance on all instances (compared to B) <u>and</u> if it is better on at least one of them. A missing value is automatically a worse performance. However, instances which could not be solved by either one of the algorithms, were not considered for the dominance relation.<br>

<br>
<br>

<h1>Visualisations</h1>
<b><FONT COLOR = "#FF0000"> Important note w.r.t. some of the following plots:</b><br>
If appropriate, we imputed performance values for failed or censored runs.
We used max + 0.3 * (max - min), in case of minimization problems,
or min - 0.3 * (max - min), in case of maximization problems.<br>
In addition, a small noise is added to the imputed values (except for the cluster matrix,
based on correlations, which is shown at the end of this page). </FONT>
<br>
<br>

<h2> Boxplots of performance values </h2>

<br>Imputing the performance values of failed or censored runs (as described in the red note at the beginning of this section):<br>
<!--begin.rcode
  plotAlgoPerfBoxplots(asscenario, impute.zero.vals = config$algo.perf.impute.zero.vals, log = config$algo.perf.log, impute.failed.runs = TRUE)
end.rcode-->

<br>Discarding the performance values of failed or censored runs:<br>
<!--begin.rcode
  plotAlgoPerfBoxplots(asscenario, impute.zero.vals = config$algo.perf.impute.zero.vals, log = config$algo.perf.log, impute.failed.runs = FALSE)
end.rcode-->

<br>
<h2> Estimated densitities of performance values </h2>

<br>Imputing the performance values of failed or censored runs (as described in the red note at the beginning of this section):<br>
<!--begin.rcode
  plotAlgoPerfDensities(asscenario, impute.zero.vals = config$algo.perf.impute.zero.vals, log = config$algo.perf.log, impute.failed.runs = TRUE)
end.rcode-->

<br>Discarding the performance values of failed or censored runs:<br>
<!--begin.rcode
  plotAlgoPerfDensities(asscenario, impute.zero.vals = config$algo.perf.impute.zero.vals, log = config$algo.perf.log, impute.failed.runs = FALSE)
end.rcode-->
<br>

<h2> Estimated cumulative distribution functions of performance values </h2>

<br>Imputing the performance values of failed runs (as described in the red note at the beginning of this section):<br>
<!--begin.rcode
  plotAlgoPerfCDFs(asscenario, impute.zero.vals = config$algo.perf.impute.zero.vals, log = config$algo.perf.log, rm.censored.runs = FALSE)
end.rcode-->

<br>Discarding the performance values of failed or censored runs:<br>
<!--begin.rcode
  plotAlgoPerfCDFs(asscenario, impute.zero.vals = config$algo.perf.impute.zero.vals, log = config$algo.perf.log)
end.rcode-->


<br>
<h2> Scatterplot matrix of the performance values </h2>
The figure underneath shows pairwise scatterplots of the performance values.<br>

<br>Imputing the performance values of failed and censored runs (as described in the red note at the beginning of this section):<br>

<!--begin.rcode, results = "asis"
  plotAlgoPerfScatterMatrix(asscenario, impute.zero.vals = config$algo.perf.impute.zero.vals, log = config$algo.perf.log)
end.rcode-->


<br>
<h2> Clustering algorithms based on their correlations </h2>
The following figure shows the correlations of the <b>ranks</b> of the performance
values. Per default it will show the correlation coefficient of spearman. Missing values were imputed <u>prior</u> to computing the correlation coefficients. The algorithms are ordered in a way that similar (highly correlated) algorithms are close to each other. Per default the clustering is based on hierarchical clustering, using Ward's method. <br>
<br>

<!--begin.rcode
  plotAlgoCorMatrix(asscenario)
end.rcode-->


</body>
</html>
